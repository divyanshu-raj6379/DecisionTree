{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting measures\n",
        "\n",
        "With more than one attribute taking part in the decision-making process, it is necessary to decide the relevance and importance of each of the attributes present in a dataset. Thus, we want to place the most relevant feature at the root node and further traverse down by splitting the nodes.\n",
        "\n",
        "As we move further down the tree, the level of impurity or uncertainty decreases, thus leading to a better classification or best split at every node. Splitting measures such as Information gain, Gini Index, etc. are used to decide the same."
      ],
      "metadata": {
        "id": "KGsYpicCy1HL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Gini Impurity: it measures the degree or probability of a particular variable being wrongly classified when it is randomly chosen.\n",
        "$G(\\mathcal{S}) = 1-\\sum_{i \\in \\mathcal {C}}p_{i}^2$, \\\n",
        "where \\\n",
        "$\\mathcal {C}$ is set of classes in dataset $\\mathcal{S}$ and \\\n",
        "$p_{i}$ is the proportion of class $i$ in $\\mathcal{S}$"
      ],
      "metadata": {
        "id": "9SZjirc8oOhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Entropy: It is a measure of the amount of uncertainty in the (data) set $\\mathcal{S}$ \n",
        "$H(\\mathcal{S})=-\\sum_{i\\in \\mathcal {C}}p_{i}\\log_{2}(p_{i})$,  \\\n",
        "where \\\n",
        "$\\mathcal {C}$ is set of classes in dataset $\\mathcal{S}$ and \\\n",
        "$p_{i}$ is the proportion of class $i$ in $\\mathcal{S}$"
      ],
      "metadata": {
        "id": "XJf4ABZJqQwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Information Gain on an attribute $\\mathcal{A}$ of $\\mathcal{S}$ is the measure of the difference in entropy from before to after the set $\\mathcal{S}$ is split on the attribute $\\mathcal{A}$ into subsets $\\mathcal{S_{1}}$, $\\mathcal{S_{2}}$,$...$, $\\mathcal{S_{m}}$\n",
        "$IG(\\mathcal{S},\\mathcal{A})=H(\\mathcal{S})-\\sum_{j=1}^{m}H(\\mathcal{S}|\\mathcal{S}_{j})$, where $H(\\mathcal{S}|\\mathcal{S}_{j})=\\frac{\\mid\\mathcal{S}_{j}\\mid}{\\mid \\mathcal{S} \\mid}.H(\\mathcal{S}_{j})$"
      ],
      "metadata": {
        "id": "5FpEdOAFvbfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ID3 Algorithm - \n",
        "ID3 stands for Iterative Dichotomiser 3 and is named such because the algorithm iteratively (repeatedly) dichotomizes(divides) features into two or more groups at each step.\n",
        "\n",
        "Invented by Ross Quinlan, ID3 uses a top-down greedy approach to build a decision tree. In simple words, the top-down approach means that we start building the tree from the top and the greedy approach means that at each iteration we select the best feature at the present moment to create a node.\n",
        "\n",
        "Most generally ID3 is only used for classification problems with nominal features only.\n",
        "\n",
        "Steps:\\\n",
        "$***$\\\n",
        "$1.$ Calculate the Information Gain of each feature.\\\n",
        "$2.$ Considering that all rows donâ€™t belong to the same class, split the dataset $S$ into subsets using the feature for which the Information Gain is maximum.\\\n",
        "$3.$ Make a decision tree node using the feature with the maximum Information gain.\\\n",
        "$4.$ If all rows belong to the same class, make the current node as a leaf node with the class as its label.\\\n",
        "$5.$ Repeat for the remaining features until we run out of all features, or the decision tree has all leaf nodes."
      ],
      "metadata": {
        "id": "hRExuMjv2Hhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "3LN-F3ewonLa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris(as_frame=True)\n",
        "X_iris = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
        "y_iris = iris.target"
      ],
      "metadata": {
        "id": "MJDH-i6C6zA5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=79)\n",
        "tree_clf.fit(X_iris, y_iris)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdIi9qH97SPi",
        "outputId": "88899026-5f22-4888-db01-9db4273fe7bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=2, random_state=79)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "from graphviz import Source"
      ],
      "metadata": {
        "id": "W8H0W_zr7kI1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_graphviz(tree_clf, \n",
        "                out_file=\"iris_tree.dot\", \n",
        "                feature_names=[\"petal length (cm)\", \"petal width (cm)\"],\n",
        "                class_names=iris.target_names,\n",
        "                rounded=True,\n",
        "                filled=True)"
      ],
      "metadata": {
        "id": "qiJlmPht7yL6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Source.from_file(\"iris_tree.dot\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "sBhDkHZ38Wy3",
        "outputId": "9b86eb16-a6b6-4844-98c2-762cc76282e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f662a4af2b0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"351pt\" height=\"314pt\"\n viewBox=\"0.00 0.00 351.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-310 347,-310 347,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M203,-306C203,-306 72,-306 72,-306 66,-306 60,-300 60,-294 60,-294 60,-235 60,-235 60,-229 66,-223 72,-223 72,-223 203,-223 203,-223 209,-223 215,-229 215,-235 215,-235 215,-294 215,-294 215,-300 209,-306 203,-306\"/>\n<text text-anchor=\"middle\" x=\"137.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) &lt;= 0.8</text>\n<text text-anchor=\"middle\" x=\"137.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.667</text>\n<text text-anchor=\"middle\" x=\"137.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 150</text>\n<text text-anchor=\"middle\" x=\"137.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 50, 50]</text>\n<text text-anchor=\"middle\" x=\"137.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M105,-179.5C105,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 105,-111.5 105,-111.5 111,-111.5 117,-117.5 117,-123.5 117,-123.5 117,-167.5 117,-167.5 117,-173.5 111,-179.5 105,-179.5\"/>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 50</text>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 0, 0]</text>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M110.09,-222.91C102.49,-211.65 94.23,-199.42 86.59,-188.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"89.39,-186 80.89,-179.67 83.59,-189.91 89.39,-186\"/>\n<text text-anchor=\"middle\" x=\"76.14\" y=\"-200.51\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M286,-187C286,-187 147,-187 147,-187 141,-187 135,-181 135,-175 135,-175 135,-116 135,-116 135,-110 141,-104 147,-104 147,-104 286,-104 286,-104 292,-104 298,-110 298,-116 298,-116 298,-175 298,-175 298,-181 292,-187 286,-187\"/>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) &lt;= 1.75</text>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 50, 50]</text>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M164.91,-222.91C170.91,-214.01 177.33,-204.51 183.53,-195.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"186.44,-197.27 189.14,-187.02 180.64,-193.35 186.44,-197.27\"/>\n<text text-anchor=\"middle\" x=\"193.9\" y=\"-207.86\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#4de88e\" stroke=\"black\" d=\"M196,-68C196,-68 99,-68 99,-68 93,-68 87,-62 87,-56 87,-56 87,-12 87,-12 87,-6 93,0 99,0 99,0 196,0 196,0 202,0 208,-6 208,-12 208,-12 208,-56 208,-56 208,-62 202,-68 196,-68\"/>\n<text text-anchor=\"middle\" x=\"147.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.168</text>\n<text text-anchor=\"middle\" x=\"147.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 54</text>\n<text text-anchor=\"middle\" x=\"147.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 49, 5]</text>\n<text text-anchor=\"middle\" x=\"147.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M190.81,-103.73C185.29,-94.97 179.45,-85.7 173.91,-76.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"176.78,-74.89 168.48,-68.3 170.85,-78.63 176.78,-74.89\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#843de6\" stroke=\"black\" d=\"M331,-68C331,-68 238,-68 238,-68 232,-68 226,-62 226,-56 226,-56 226,-12 226,-12 226,-6 232,0 238,0 238,0 331,0 331,0 337,0 343,-6 343,-12 343,-12 343,-56 343,-56 343,-62 337,-68 331,-68\"/>\n<text text-anchor=\"middle\" x=\"284.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.043</text>\n<text text-anchor=\"middle\" x=\"284.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 46</text>\n<text text-anchor=\"middle\" x=\"284.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 45]</text>\n<text text-anchor=\"middle\" x=\"284.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M241.82,-103.73C247.26,-94.97 253.01,-85.7 258.48,-76.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"261.52,-78.64 263.82,-68.3 255.57,-74.95 261.52,-78.64\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit-Learn uses *Classification and Regression Tree (CART)* algorith to train decision trees.The algorith works by first splitting the training set into two subsets using a single feature $k$ and a threshold $t_{k}$ (e.g. \"petal width (cm)\" $\\le 0.8$).\n",
        "\n",
        "It searches for the pair $(k,t_{k})$ that produces the purest subsets, weighted by their size.\n",
        "\n",
        "CART cost function for minimization:\n",
        "\n",
        "$J(k,t_{k})=\\frac{m_{left}}{m}G_{left}+\\frac{m_{right}}{m}G_{right}$, \n",
        "\n",
        "where \\\n",
        "$G_{left/right}$ measures the impurity of left/right subset, and \\\n",
        "$m_{left/right}$ is the cardinality of left/right subset."
      ],
      "metadata": {
        "id": "MgVOCZI_AKhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(tree_clf.tree_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hVECb-d8dNf",
        "outputId": "a5b235fa-c287-42ba-f3ef-a3891d6b8e8c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on Tree object:\n",
            "\n",
            "class Tree(builtins.object)\n",
            " |  Array-based representation of a binary decision tree.\n",
            " |  \n",
            " |  The binary tree is represented as a number of parallel arrays. The i-th\n",
            " |  element of each array holds information about the node `i`. Node 0 is the\n",
            " |  tree's root. You can find a detailed description of all arrays in\n",
            " |  `_tree.pxd`. NOTE: Some of the arrays only apply to either leaves or split\n",
            " |  nodes, resp. In this case the values of nodes of the other type are\n",
            " |  arbitrary!\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  node_count : int\n",
            " |      The number of nodes (internal nodes + leaves) in the tree.\n",
            " |  \n",
            " |  capacity : int\n",
            " |      The current capacity (i.e., size) of the arrays, which is at least as\n",
            " |      great as `node_count`.\n",
            " |  \n",
            " |  max_depth : int\n",
            " |      The depth of the tree, i.e. the maximum depth of its leaves.\n",
            " |  \n",
            " |  children_left : array of int, shape [node_count]\n",
            " |      children_left[i] holds the node id of the left child of node i.\n",
            " |      For leaves, children_left[i] == TREE_LEAF. Otherwise,\n",
            " |      children_left[i] > i. This child handles the case where\n",
            " |      X[:, feature[i]] <= threshold[i].\n",
            " |  \n",
            " |  children_right : array of int, shape [node_count]\n",
            " |      children_right[i] holds the node id of the right child of node i.\n",
            " |      For leaves, children_right[i] == TREE_LEAF. Otherwise,\n",
            " |      children_right[i] > i. This child handles the case where\n",
            " |      X[:, feature[i]] > threshold[i].\n",
            " |  \n",
            " |  feature : array of int, shape [node_count]\n",
            " |      feature[i] holds the feature to split on, for the internal node i.\n",
            " |  \n",
            " |  threshold : array of double, shape [node_count]\n",
            " |      threshold[i] holds the threshold for the internal node i.\n",
            " |  \n",
            " |  value : array of double, shape [node_count, n_outputs, max_n_classes]\n",
            " |      Contains the constant prediction value of each node.\n",
            " |  \n",
            " |  impurity : array of double, shape [node_count]\n",
            " |      impurity[i] holds the impurity (i.e., the value of the splitting\n",
            " |      criterion) at node i.\n",
            " |  \n",
            " |  n_node_samples : array of int, shape [node_count]\n",
            " |      n_node_samples[i] holds the number of training samples reaching node i.\n",
            " |  \n",
            " |  weighted_n_node_samples : array of int, shape [node_count]\n",
            " |      weighted_n_node_samples[i] holds the weighted number of training samples\n",
            " |      reaching node i.\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __getstate__(...)\n",
            " |      Getstate re-implementation, for pickling.\n",
            " |  \n",
            " |  __reduce__(...)\n",
            " |      Reduce re-implementation, for pickling.\n",
            " |  \n",
            " |  __setstate__(...)\n",
            " |      Setstate re-implementation, for unpickling.\n",
            " |  \n",
            " |  apply(...)\n",
            " |      Finds the terminal region (=leaf node) for each sample in X.\n",
            " |  \n",
            " |  compute_feature_importances(...)\n",
            " |      Computes the importance of each feature (aka variable).\n",
            " |  \n",
            " |  compute_partial_dependence(...)\n",
            " |      Partial dependence of the response on the ``target_feature`` set.\n",
            " |      \n",
            " |      For each sample in ``X`` a tree traversal is performed.\n",
            " |      Each traversal starts from the root with weight 1.0.\n",
            " |      \n",
            " |      At each non-leaf node that splits on a target feature, either\n",
            " |      the left child or the right child is visited based on the feature\n",
            " |      value of the current sample, and the weight is not modified.\n",
            " |      At each non-leaf node that splits on a complementary feature,\n",
            " |      both children are visited and the weight is multiplied by the fraction\n",
            " |      of training samples which went to each child.\n",
            " |      \n",
            " |      At each leaf, the value of the node is multiplied by the current\n",
            " |      weight (weights sum to 1 for all visited terminal nodes).\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : view on 2d ndarray, shape (n_samples, n_target_features)\n",
            " |          The grid points on which the partial dependence should be\n",
            " |          evaluated.\n",
            " |      target_features : view on 1d ndarray, shape (n_target_features)\n",
            " |          The set of target features for which the partial dependence\n",
            " |          should be evaluated.\n",
            " |      out : view on 1d ndarray, shape (n_samples)\n",
            " |          The value of the partial dependence function on each grid\n",
            " |          point.\n",
            " |  \n",
            " |  decision_path(...)\n",
            " |      Finds the decision path (=node) for each sample in X.\n",
            " |  \n",
            " |  predict(...)\n",
            " |      Predict target for X.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __new__(*args, **kwargs) from builtins.type\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  capacity\n",
            " |  \n",
            " |  children_left\n",
            " |  \n",
            " |  children_right\n",
            " |  \n",
            " |  feature\n",
            " |  \n",
            " |  impurity\n",
            " |  \n",
            " |  max_depth\n",
            " |  \n",
            " |  max_n_classes\n",
            " |  \n",
            " |  n_classes\n",
            " |  \n",
            " |  n_features\n",
            " |  \n",
            " |  n_leaves\n",
            " |  \n",
            " |  n_node_samples\n",
            " |  \n",
            " |  n_outputs\n",
            " |  \n",
            " |  node_count\n",
            " |  \n",
            " |  threshold\n",
            " |  \n",
            " |  value\n",
            " |  \n",
            " |  weighted_n_node_samples\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __pyx_vtable__ = <capsule object NULL>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree_clf.predict_proba([[5.1, 1.5]]).round(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOP44YY3-R58",
        "outputId": "414a0079-8b0a-4171-dd33-59c1b2fbc944"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.   , 0.907, 0.093]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris.target_names[tree_clf.predict([[5.1, 1.5]])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JKscZWK_OID",
        "outputId": "e49824c2-1e7c-4893-c36f-573d1d93b464"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['versicolor'], dtype='<U10')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}